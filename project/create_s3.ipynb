{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Pre-requisite steps - Create an IAM user and save the credentials\n",
    "\n",
    "### Add aws.credentials to .gitignore\n",
    "1. echo \"aws.credentials\" >> .gitignore\n",
    "\n",
    "### Set up an AWS user whose credentials you are going to use\n",
    "1. Launch AWS (I did it from the Udacity console\n",
    "1. Navigate to Services --> IAM --> Users\n",
    "1. Choose a name of your choice.\n",
    "1. Select \"Programmatic access\" as the access type. Click Next.\n",
    "1. Choose the Attach existing policies directly tab, and select the \"AdministratorAccess\". Click Next.\n",
    "1. Skip adding any tags. Click Next.\n",
    "1. Review and create the user. It will show you a pair of access key ID and secret.\n",
    "1. Take note of the pair of access key ID and secret. This pair is collectively known as Access key.\n",
    "1. Add the access key id and the secret key id to the aws.credentials file \n",
    "\n",
    "```\n",
    "[AWS]\n",
    "KEY=#####################\n",
    "SECRET=#################################\n",
    "\n",
    "```\n",
    "\n",
    "see [Udacity exercise](https://learn.udacity.com/nanodegrees/nd027-ent-rbs/parts/cd0055/lessons/2ea9a35d-4276-48f0-aba8-3fd5d9057a7c/concepts/69da665c-acbe-4dcc-8846-46434098d418) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Load AWS config from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DB_NAME</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DB_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARN</td>\n",
       "      <td>arn:aws:iam::109203719027:role/dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Param                                   Value\n",
       "0        DB_CLUSTER_TYPE                              multi-node\n",
       "1           DB_NUM_NODES                                       4\n",
       "2           DB_NODE_TYPE                               dc2.large\n",
       "3  DB_CLUSTER_IDENTIFIER                              dwhCluster\n",
       "4                DB_NAME                                     dwh\n",
       "5                DB_USER                                 dwhuser\n",
       "6            DB_PASSWORD                                Passw0rd\n",
       "7                DB_PORT                                    5439\n",
       "8          IAM_ROLE_NAME                                 dwhRole\n",
       "9                    ARN  arn:aws:iam::109203719027:role/dwhRole"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('aws.cfg'))\n",
    "\n",
    "DB_CLUSTER_TYPE        = config.get(\"CLUSTER\",\"DB_CLUSTER_TYPE\")\n",
    "DB_NUM_NODES           = config.get(\"CLUSTER\",\"DB_NUM_NODES\")\n",
    "DB_NODE_TYPE           = config.get(\"CLUSTER\",\"DB_NODE_TYPE\")\n",
    "\n",
    "DB_CLUSTER_IDENTIFIER  = config.get(\"CLUSTER\",\"DB_CLUSTER_IDENTIFIER\")\n",
    "DB_NAME                = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DB_USER                = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DB_PASSWORD         = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DB_PORT                = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "\n",
    "IAM_ROLE_NAME          = config.get(\"IAM_ROLE\", \"IAM_ROLE_NAME\")\n",
    "ARN                    = config.get(\"IAM_ROLE\", \"ARN\")\n",
    "\n",
    "(DB_USER, DB_PASSWORD, DB_NAME)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DB_CLUSTER_TYPE\", \"DB_NUM_NODES\", \"DB_NODE_TYPE\", \"DB_CLUSTER_IDENTIFIER\", \n",
    "                   \"DB_NAME\", \"DB_USER\", \"DB_PASSWORD\", \"DB_PORT\", \"IAM_ROLE_NAME\",\"ARN\"],\n",
    "              \"Value\":\n",
    "                  [DB_CLUSTER_TYPE, DB_NUM_NODES, DB_NODE_TYPE, DB_CLUSTER_IDENTIFIER, \n",
    "                   DB_NAME, DB_USER, DB_PASSWORD, DB_PORT, IAM_ROLE_NAME, ARN],\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read in AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config.read_file(open('aws.credentials'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create client for S3\n",
    "**Note**: We are creating these resources in the the **us-west-2** region. Choose the same region in the your AWS web console to the see these resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create S3 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating s3 bucket\n"
     ]
    }
   ],
   "source": [
    "S3_BUCKET  = \"tom-baird-capstone-project-2\"\n",
    "print(\"1.1 Creating s3 bucket\") \n",
    "try:\n",
    "    s3.create_bucket(Bucket=S3_BUCKET, CreateBucketConfiguration={\n",
    "                    'LocationConstraint': 'us-west-2'})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Check that the new bucket exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "  aws-logs-109203719027-us-east-1\n",
      "  tom-baird-capstone-project-2\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3',\n",
    "                   region_name=\"us-west-2\",\n",
    "                   aws_access_key_id=KEY,\n",
    "                   aws_secret_access_key=SECRET)\n",
    "response = s3_client.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "print('Existing buckets:')\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### This will delete the bucket (unless it contains files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom-baird-capstone-project-2 has been deleted successfully !!!\n"
     ]
    }
   ],
   "source": [
    "# my_bucket = 'tom-baird-capstone-project-2'\n",
    "# objects = s3_client.list_objects_v2(Bucket=my_bucket)\n",
    "# fileCount = objects['KeyCount']\n",
    "\n",
    "# if fileCount == 0:\n",
    "#  response = s3_client.delete_bucket(Bucket=my_bucket)\n",
    "#  print(\"{} has been deleted successfully !!!\".format(my_bucket))\n",
    "# else:\n",
    "#  print(\"{} is not empty {} objects present\".format(my_bucket,fileCount))\n",
    "#  print(\"Please make sure S3 bucket is empty before deleting it !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3.meta.client.upload_file('immigration_data_sample.csv','tom-baird-capstone-project-2','immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Check the files in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_bucket = s3.Bucket('tom-baird-capstone-project-2')\n",
    "# my_bucket = s3.Bucket('aws-logs-109203719027-us-east-1')\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.all():\n",
    "    print(my_bucket_object.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Delete the sample file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'Q34K7V0A4CFQ32R3',\n",
       "  'HostId': 'ITs24U4s2M4tX3YjN110ctQOPJABZLZUMC2fbiZKw5mivT8tNTqokx7OoB0zDQFygZJO7mO+yl0=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'ITs24U4s2M4tX3YjN110ctQOPJABZLZUMC2fbiZKw5mivT8tNTqokx7OoB0zDQFygZJO7mO+yl0=',\n",
       "   'x-amz-request-id': 'Q34K7V0A4CFQ32R3',\n",
       "   'date': 'Thu, 08 Dec 2022 09:17:26 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s3.Object('tom-baird-capstone-project-2', 'immigration_data_sample.csv').delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create clients for IAM, EC2 and Redshift\n",
    "**Note**: We are creating these resources in the the **us-west-2** region. Choose the same region in the your AWS web console to the see these resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::109203719027:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### - Create a [RedShift Cluster](https://console.aws.amazon.com/redshiftv2/home)\n",
    "#### - For complete arguments to `create_cluster`, see [docs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html#Redshift.Client.create_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 Creating a Redshift cluster\n"
     ]
    }
   ],
   "source": [
    "print(\"1.4 Creating a Redshift cluster\")\n",
    "\n",
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DB_CLUSTER_TYPE,\n",
    "        NodeType=DB_NODE_TYPE,\n",
    "        NumberOfNodes=int(DB_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DB_NAME,\n",
    "        ClusterIdentifier=DB_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DB_USER,\n",
    "        MasterUserPassword=DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Wait until cluster is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Waiting for cluster to become available\n",
      "Cluster Available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "while redshift.describe_clusters(ClusterIdentifier=DB_CLUSTER_IDENTIFIER)['Clusters'][0]['ClusterStatus']!='available':\n",
    "    print ('Waiting for cluster to become available')\n",
    "    time.sleep(10)\n",
    "    i += 1\n",
    "    \n",
    "    if i > 30:\n",
    "#       Error\n",
    "        print('Error - cluster not available after 5 minutes')\n",
    "        exit(1)\n",
    "        \n",
    "# TODO - handle error better    \n",
    "print('Cluster Available')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create a function to parse the cluster details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k,a v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Display the cluster details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_ENDPOINT ::  dwhcluster.csasogv133my.us-west-2.redshift.amazonaws.com\n",
      "DB_ROLE_ARN ::  arn:aws:iam::109203719027:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "time.sleep(10)\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DB_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n",
    "\n",
    "\n",
    "DB_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DB_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DB_ENDPOINT :: \", DB_ENDPOINT)\n",
    "print(\"DB_ROLE_ARN :: \", DB_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Delete the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands set to stop the Redshift cluster\n"
     ]
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DB_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!\n",
    "\n",
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DB_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n",
    "\n",
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "iam.detach_role_policy(RoleName=IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=IAM_ROLE_NAME)\n",
    "#### CAREFUL!!\n",
    "\n",
    "print('Commands set to stop the Redshift cluster')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
